{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import dirichlet, norm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR(1) with uniform prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 69 pays, longueur 27 ans (entre 1998 et 2024), normalisé entre 0 et 1\n",
    "GDP = pd.read_csv('../Data preprocessing/GDP_yearly_length_27_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_global = pd.read_csv('../Data preprocessing/GDP_yearly_27_global_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = GDP.drop(GDP.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Advanced Economies</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Bolivia</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Botswana</th>\n",
       "      <th>Canada</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>Taiwan, China</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>United States</th>\n",
       "      <th>World (WBG members)</th>\n",
       "      <th>South Africa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058263</td>\n",
       "      <td>0.419842</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>0.075248</td>\n",
       "      <td>0.065662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.058236</td>\n",
       "      <td>0.071799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059256</td>\n",
       "      <td>0.056431</td>\n",
       "      <td>0.036479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>0.169978</td>\n",
       "      <td>0.063511</td>\n",
       "      <td>0.035017</td>\n",
       "      <td>0.032060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131093</td>\n",
       "      <td>0.409848</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>0.148157</td>\n",
       "      <td>0.136995</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>0.065312</td>\n",
       "      <td>0.089006</td>\n",
       "      <td>0.147254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.107926</td>\n",
       "      <td>0.128310</td>\n",
       "      <td>0.073154</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.087227</td>\n",
       "      <td>0.146532</td>\n",
       "      <td>0.120167</td>\n",
       "      <td>0.082889</td>\n",
       "      <td>0.089510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159332</td>\n",
       "      <td>0.352416</td>\n",
       "      <td>0.102593</td>\n",
       "      <td>0.176508</td>\n",
       "      <td>0.158882</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.034685</td>\n",
       "      <td>0.086347</td>\n",
       "      <td>0.108492</td>\n",
       "      <td>0.176202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.145398</td>\n",
       "      <td>0.152396</td>\n",
       "      <td>0.102717</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.076927</td>\n",
       "      <td>0.100792</td>\n",
       "      <td>0.133988</td>\n",
       "      <td>0.103997</td>\n",
       "      <td>0.127994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187174</td>\n",
       "      <td>0.218249</td>\n",
       "      <td>0.147604</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.193231</td>\n",
       "      <td>0.124303</td>\n",
       "      <td>0.054367</td>\n",
       "      <td>0.130058</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>0.223374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070471</td>\n",
       "      <td>0.187079</td>\n",
       "      <td>0.188187</td>\n",
       "      <td>0.157387</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.116652</td>\n",
       "      <td>0.012801</td>\n",
       "      <td>0.158818</td>\n",
       "      <td>0.129927</td>\n",
       "      <td>0.182160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Advanced Economies  Argentina  Australia   Austria   Belgium  Bulgaria  \\\n",
       "0            0.000000   0.465062   0.000000  0.000000  0.000000  0.078101   \n",
       "1            0.058263   0.419842   0.043460  0.075248  0.065662  0.000000   \n",
       "2            0.131093   0.409848   0.075163  0.148157  0.136995  0.036144   \n",
       "3            0.159332   0.352416   0.102593  0.176508  0.158882  0.070884   \n",
       "4            0.187174   0.218249   0.147604  0.209524  0.193231  0.124303   \n",
       "\n",
       "    Bolivia    Brazil  Botswana    Canada  ...  Slovakia  Slovenia    Sweden  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  ...  0.004087  0.000000  0.000000   \n",
       "1  0.002935  0.006361  0.058236  0.071799  ...  0.000000  0.059256  0.056431   \n",
       "2  0.021531  0.065312  0.089006  0.147254  ...  0.006259  0.107926  0.128310   \n",
       "3  0.034685  0.086347  0.108492  0.176202  ...  0.031499  0.145398  0.152396   \n",
       "4  0.054367  0.130058  0.168572  0.223374  ...  0.070471  0.187079  0.188187   \n",
       "\n",
       "   Thailand    Turkey  Taiwan, China   Uruguay  United States  \\\n",
       "0  0.000000  0.015166       0.000000  0.193577       0.000000   \n",
       "1  0.036479  0.000000       0.043589  0.169978       0.063511   \n",
       "2  0.073154  0.031237       0.087227  0.146532       0.120167   \n",
       "3  0.102717  0.003282       0.076927  0.100792       0.133988   \n",
       "4  0.157387  0.032078       0.116652  0.012801       0.158818   \n",
       "\n",
       "   World (WBG members)  South Africa  \n",
       "0             0.000000      0.000000  \n",
       "1             0.035017      0.032060  \n",
       "2             0.082889      0.089510  \n",
       "3             0.103997      0.127994  \n",
       "4             0.129927      0.182160  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier exemple avec p(yi∣θk) gaussienne \n",
    "(yi gaussienne de moyenne θk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Étape 1: Initialisation ---\n",
    "def initialize_model(y, K, e0=1.0):\n",
    "    \"\"\"\n",
    "    Initialise les paramètres du modèle.\n",
    "    y: Liste des séries temporelles [N x T]\n",
    "    K: Nombre de groupes\n",
    "    e0: Hyperparamètre du Dirichlet\n",
    "    \"\"\"\n",
    "    N, T = y.shape\n",
    "    eta = dirichlet.rvs([e0] * K, size=1).flatten()  # Dirichlet prior for eta\n",
    "    S = np.random.choice(K, size=N)  # Random initial classification\n",
    "    theta = [np.random.randn(T) for _ in range(K)]  # Paramètres pour chaque groupe\n",
    "    return eta, S, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Étape 2: Échantillonnage de S ---\n",
    "def sample_S(y, theta, eta):\n",
    "    \"\"\"\n",
    "    Échantillonne les indicateurs de groupe S.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    K = len(theta)\n",
    "    S = np.zeros(N, dtype=int)\n",
    "    for i in range(N):\n",
    "        probs = [\n",
    "            norm.pdf(y[i], loc=theta[k]).prod() * eta[k]  # Probabilité conditionnelle p(yi∣θk) gaussienne\n",
    "            for k in range(K)\n",
    "        ]\n",
    "        probs = np.array(probs)\n",
    "        probs /= probs.sum()  # Normalisation\n",
    "        S[i] = np.random.choice(K, p=probs)  # Échantillonnage\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Étape 3: Mise à jour des paramètres ---\n",
    "def update_theta(y, S, K):\n",
    "    \"\"\"\n",
    "    Met à jour les paramètres spécifiques aux groupes (theta).\n",
    "    \"\"\"\n",
    "    T = y.shape[1]\n",
    "    theta = []\n",
    "    for k in range(K):\n",
    "        group_data = y[S == k]\n",
    "        if len(group_data) > 0:\n",
    "            theta_k = group_data.mean(axis=0)  # Posterior mean (simple estimation)\n",
    "        else:\n",
    "            theta_k = np.random.randn(T)  # Cas sans données\n",
    "        theta.append(theta_k)\n",
    "    return theta\n",
    "\n",
    "def update_eta(S, K, e0=1.0):\n",
    "    \"\"\"\n",
    "    Met à jour les paramètres eta (structure d'ignorance).\n",
    "    \"\"\"\n",
    "    counts = np.bincount(S, minlength=K) + e0  # Comptes augmentés par le prior\n",
    "    return dirichlet.rvs(counts, size=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Étape 4: MCMC ---\n",
    "def mcmc(y, K, num_iter=1000, e0=1.0):\n",
    "    \"\"\"\n",
    "    Effectue l'estimation via MCMC.\n",
    "    \"\"\"\n",
    "    eta, S, theta = initialize_model(y, K, e0)\n",
    "    for iteration in range(num_iter):\n",
    "        # Échantillonnage de S\n",
    "        S = sample_S(y, theta, eta)\n",
    "        # Mise à jour de theta\n",
    "        theta = update_theta(y, S, K)\n",
    "        # Mise à jour de eta\n",
    "        eta = update_eta(S, K, e0)\n",
    "    return S, theta, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification estimée :  [1 2 0 2 1 1 0 1 2 0 2 2 1 1 1 1 1 0 2 2 2 2 1 2 0 0 2 2 0 0 1 0 1 1 1 1 1\n",
      " 2 0 1 0 0 1 2 1 2 0 2 2 2 0 0 2 2 1 2 1 2 1 0 2 2 2 2 1 2 0 0 2 0 2 2 0 2\n",
      " 0 1 2 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 2 2 2 0 1 0 2]\n",
      "Paramètres des groupes :  [array([-1.43885876, -0.28508876,  0.07423943, -0.56848096, -0.06911439,\n",
      "        0.84361014,  1.71529438,  0.00278895, -0.04675652, -0.21411054,\n",
      "       -1.91502398, -0.17995909,  0.53696021,  2.1140656 ,  0.09221716,\n",
      "        0.31718667,  0.1964794 , -1.17957364,  0.94882226,  0.83776001,\n",
      "        0.85822083, -0.91832784,  1.35476824, -1.33344936,  0.48575812,\n",
      "        2.03911007, -1.10031333, -0.40622436,  0.24109638, -0.6489704 ,\n",
      "       -1.97050145,  0.09435958, -0.91618468,  0.39386854, -0.93195056,\n",
      "        1.21101961, -0.66223164, -0.34742302,  0.88112607, -1.15063722,\n",
      "        0.18146311,  1.35918336, -1.64153013,  0.34284287,  0.40648783,\n",
      "        0.99553769, -1.35064288, -1.24120905,  0.54834596,  0.32916065]), array([ 0.54155319, -0.36219601, -0.53265227,  0.77784223,  1.37590764,\n",
      "        0.93466211, -0.50780346, -0.43416067,  0.01711069,  1.39884883,\n",
      "       -0.42284194, -0.42662338, -1.16971329, -1.09107281,  1.09596296,\n",
      "        1.761505  , -0.08168565,  0.97035416,  0.180252  , -0.59834537,\n",
      "        0.10572223,  1.43624229,  0.33393522,  1.63456245, -2.73257666,\n",
      "        0.90022625,  0.03534389, -0.17454354,  0.29055085, -2.01980645,\n",
      "       -0.33133081,  0.41684959,  1.45760661, -0.3497029 , -0.95289816,\n",
      "       -0.30272495,  0.85939863,  0.35362472, -0.26184432,  0.17059862,\n",
      "        0.12305266,  1.21125067, -1.11389661, -0.50538779, -0.42598711,\n",
      "       -1.50493534,  0.28774155, -0.06247391,  0.22389944, -0.41191982]), array([ 0.45862031, -0.33834982,  0.80786561,  1.84290032, -0.26775322,\n",
      "       -0.09114548,  1.39789519,  0.92350009, -0.36374174,  0.56103775,\n",
      "       -0.36543972, -0.32975821,  0.31455413, -1.755013  , -1.56252024,\n",
      "       -0.49121307, -0.94972867,  0.39474327, -0.83483595, -1.37657279,\n",
      "        1.54799719, -0.23421193,  0.0868052 , -1.32253092, -0.784215  ,\n",
      "        0.03746554, -1.29668248,  0.27274486, -0.56684564, -0.05445984,\n",
      "       -0.75576971,  1.72867829,  0.08087296, -1.22240537,  0.77072496,\n",
      "       -1.32714654,  0.18640668, -1.9481625 , -1.56774383,  0.14012713,\n",
      "        0.93760689, -0.23360042, -0.12400072, -0.50754279, -1.34196136,\n",
      "       -0.61606712, -0.2392252 ,  1.31074764,  0.17229165, -1.84474038])]\n",
      "Paramètres eta :  [0.385822   0.26430301 0.34987498]\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données synthétiques\n",
    "\n",
    "# Génération de données synthétiques\n",
    "np.random.seed(42)\n",
    "N, T, K = 100, 50, 3\n",
    "true_theta = [np.random.randn(T) for _ in range(K)]\n",
    "y = np.vstack([np.random.randn(1, T) + true_theta[k] for k in np.random.choice(K, N)])\n",
    "\n",
    "# Estimation MCMC\n",
    "S_est, theta_est, eta_est = mcmc(y, K, num_iter=500)\n",
    "\n",
    "print(\"Classification estimée : \", S_est)\n",
    "print(\"Paramètres des groupes : \", theta_est)\n",
    "print(\"Paramètres eta : \", eta_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34285941, -2.07690054, -0.02012467, ..., -0.55421566,\n",
       "         0.70420584,  0.3653095 ],\n",
       "       [ 0.01546602, -2.23205831,  0.22764107, ...,  1.28610076,\n",
       "        -1.19044683, -1.39997055],\n",
       "       [-0.27099921,  0.43721934, -0.96957239, ..., -0.78443008,\n",
       "         1.36211272,  1.4303267 ],\n",
       "       ...,\n",
       "       [ 0.51450932, -1.07085069, -1.79038001, ..., -1.84184646,\n",
       "        -0.20222532,  0.68043279],\n",
       "       [-1.33553995, -1.58544234, -0.24076355, ..., -3.07086435,\n",
       "         0.7562848 ,  1.25141375],\n",
       "       [-0.98886192,  1.51990591, -0.36214154, ...,  0.70992497,\n",
       "         0.58586527, -3.68414091]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # à tracer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 27)\n",
      "Classification estimée :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Paramètres des groupes :  [array([-0.3042521 , -0.11670463, -0.3473727 , -0.53600333, -0.30915443,\n",
      "       -0.27934743,  0.89081317, -0.89444088,  1.9536459 , -0.66514828,\n",
      "        0.86910079, -1.42708004, -0.66648318, -0.22104584, -0.86772683,\n",
      "        0.57914114,  0.56361525, -0.70822635, -1.81519983,  0.62686454,\n",
      "        0.07987199, -0.48536948, -0.57860071, -0.70380732,  0.84741842,\n",
      "       -0.33620734,  1.37977526]), array([0.03085638, 0.06074844, 0.11206989, 0.13884558, 0.16606907,\n",
      "       0.20141824, 0.25704613, 0.31076316, 0.3797597 , 0.45083692,\n",
      "       0.48009911, 0.42329402, 0.47721469, 0.51991825, 0.53946059,\n",
      "       0.57033192, 0.60810629, 0.64955105, 0.69165072, 0.75201168,\n",
      "       0.8053718 , 0.84722232, 0.75697621, 0.88197098, 0.95204807,\n",
      "       0.98845817, 0.41973416]), array([ 2.37127377,  0.66286393,  2.25688412,  0.70405373, -0.36271871,\n",
      "        1.63913692, -0.15827916,  2.43177159, -0.50818738,  0.93187343,\n",
      "        0.00554149, -1.06827061, -0.89371506, -2.40279331, -0.06586791,\n",
      "        0.52121547, -2.1645169 , -3.11798073, -0.89452408,  0.10132473,\n",
      "       -0.9980843 ,  0.15459998, -0.58603398, -1.39808833,  0.72084409,\n",
      "        0.30878747, -0.3775407 ])]\n",
      "Paramètres eta :  [0.0207677  0.97414521 0.00508708]\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données réelles normalisées\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conversion en tableau NumPy\n",
    "y = GDP.values.T  # Transpose pour avoir (N, T)\n",
    "print(y.shape)  # Doit afficher (69, 27)\n",
    "\n",
    "K = 3  # Nombre de clusters\n",
    "num_iter = 500  # Nombre d'itérations pour le MCMC\n",
    "\n",
    "# Estimation MCMC\n",
    "S_est, theta_est, eta_est = mcmc(y, K, num_iter)\n",
    "\n",
    "print(\"Classification estimée : \", S_est)\n",
    "print(\"Paramètres des groupes : \", theta_est)\n",
    "print(\"Paramètres eta : \", eta_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification estimée :  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Paramètres des groupes :  [array([ 1.74169077e+00, -3.81474571e-01,  4.25480967e-01,  1.09195970e+00,\n",
      "       -1.89837742e+00, -8.37492785e-01, -1.23806434e-03, -1.18768745e+00,\n",
      "       -6.75776988e-01, -1.79102207e+00, -9.14564488e-01, -8.18783113e-01,\n",
      "        1.62320855e+00,  6.30259872e-01, -1.36151115e+00, -5.45606038e-01,\n",
      "        3.16015286e-01, -7.85183851e-01, -6.70778772e-01,  1.63083555e+00,\n",
      "       -1.22885632e+00,  2.08056312e+00, -1.24419540e+00, -2.11153265e+00,\n",
      "        1.62670924e+00,  2.98005680e-01, -1.55600629e-01]), array([ 3.86532725e-01, -1.44286948e+00, -5.56678995e-01,  9.53890045e-01,\n",
      "       -6.86679973e-01, -7.04344431e-01,  1.15052783e+00, -5.36561176e-02,\n",
      "        3.52715559e-01, -1.42268760e+00,  1.60169876e-03,  1.38842350e+00,\n",
      "       -1.80436284e+00, -9.76998604e-01,  1.21490237e+00,  3.84131575e-01,\n",
      "       -8.10465459e-01, -9.10127292e-02, -3.01632934e-01, -2.24542588e+00,\n",
      "        6.10755106e-02, -1.55890424e+00,  2.72563730e-01, -1.59276520e+00,\n",
      "        8.62332870e-01, -1.00344387e-01, -1.19548329e+00]), array([0.03056193, 0.03159131, 0.03302868, 0.03367522, 0.03446686,\n",
      "       0.03547285, 0.03693452, 0.03838303, 0.040069  , 0.04181609,\n",
      "       0.04262726, 0.04184442, 0.04374278, 0.04523673, 0.04638075,\n",
      "       0.04766686, 0.04906987, 0.05051679, 0.05183565, 0.05363662,\n",
      "       0.05537574, 0.05682815, 0.05502658, 0.05864292, 0.06050313,\n",
      "       0.06216703, 0.04727392])]\n",
      "Paramètres eta :  [0.00941036 0.00107084 0.9895188 ]\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données réelles normalisées sur l'ensemble\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conversion en tableau NumPy\n",
    "y_global = GDP_global.values.T  # Transpose pour avoir (N, T)\n",
    "\n",
    "K = 3  # Nombre de clusters\n",
    "num_iter = 500  # Nombre d'itérations pour le MCMC\n",
    "\n",
    "# Estimation MCMC\n",
    "S_est, theta_est, eta_est = mcmc(y_global, K, num_iter)\n",
    "\n",
    "print(\"Classification estimée : \", S_est)\n",
    "print(\"Paramètres des groupes : \", theta_est)\n",
    "print(\"Paramètres eta : \", eta_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième exemple avec un modèle ARMA(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_S_arma(y, theta, eta, p, q):\n",
    "    \"\"\"\n",
    "    Échantillonne les indicateurs de groupe S.\n",
    "    y : séries temporelles\n",
    "    theta : paramètres ARMA pour chaque groupe\n",
    "    eta : probabilités de groupe\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    K = len(eta)\n",
    "    log_probs = np.zeros((N, K))\n",
    "    \n",
    "    for k in range(K):\n",
    "        for i in range(N):\n",
    "            log_probs[i, k] = np.log(eta[k]) + arma_log_likelihood(y[i], theta[k], p, q)\n",
    "    \n",
    "    # Normalisation pour obtenir des probabilités\n",
    "    probs = np.exp(log_probs - log_probs.max(axis=1, keepdims=True))\n",
    "    probs /= probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Échantillonnage des groupes\n",
    "    S = np.array([np.random.choice(K, p=probs[i]) for i in range(N)])\n",
    "    return S\n",
    "\n",
    "def update_theta_arma(y, S, K, p, q):\n",
    "    \"\"\"\n",
    "    Met à jour les paramètres ARMA pour chaque groupe.\n",
    "    \"\"\"\n",
    "    theta = []\n",
    "    for k in range(K):\n",
    "        group_data = y[S == k]  # Séries assignées au groupe k\n",
    "        theta_k = estimate_arma_params(group_data, p, q)\n",
    "        theta.append(theta_k)\n",
    "    return theta\n",
    "\n",
    "def arma_log_likelihood(y, theta, p, q):\n",
    "    \"\"\"\n",
    "    Calcule la vraisemblance logarithmique d'un modèle ARMA.\n",
    "    y : série temporelle\n",
    "    theta : paramètres ARMA\n",
    "    \"\"\"\n",
    "    # Placeholder : remplacer par une vraie implémentation\n",
    "    return -0.5 * np.sum((y - np.convolve(y, theta, mode='same'))**2)\n",
    "\n",
    "def estimate_arma_params(y, p, q):\n",
    "    \"\"\"\n",
    "    Estime les paramètres ARMA pour un ensemble de séries.\n",
    "    \"\"\"\n",
    "    # Placeholder : remplacer par une vraie implémentation\n",
    "    return np.random.randn(p + q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_arma(y, K, p, q, num_iterations, e0=1.0):\n",
    "    \"\"\"\n",
    "    Exécute une chaîne MCMC pour estimer les paramètres du modèle ARMA avec structure d'ignorance pour eta.\n",
    "    y : séries temporelles (array [N x T])\n",
    "    K : nombre de groupes\n",
    "    p : ordre AR\n",
    "    q : ordre MA\n",
    "    num_iterations : nombre d'itérations de MCMC\n",
    "    e0 : hyperparamètre de la distribution Dirichlet pour eta\n",
    "    \"\"\"\n",
    "    # Initialisation des paramètres\n",
    "    eta, S, theta = initialize_model(y, K, e0)\n",
    "\n",
    "    for iter in range(num_iterations):\n",
    "        # Étape (a) : Échantillonnage des groupes S\n",
    "        S = sample_S_arma(y, theta, eta, p, q)\n",
    "\n",
    "        # Étape (b.1) : Mise à jour des paramètres ARMA pour chaque groupe\n",
    "        theta = update_theta_arma(y, S, K, p, q)\n",
    "\n",
    "        # Étape (b.2) : Mise à jour des probabilités de groupe eta\n",
    "        eta = update_eta(S, K, e0)\n",
    "\n",
    "        # Diagnostics ou suivi des progrès\n",
    "        if iter % 100 == 0:\n",
    "            print(f\"Iteration {iter}: eta = {eta}\")\n",
    "\n",
    "    return S, theta, eta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: eta = [0.13734109 0.56517378 0.29748513]\n",
      "Iteration 100: eta = [0.2842857  0.13624712 0.57946718]\n",
      "Iteration 200: eta = [0.29039462 0.63451304 0.07509233]\n",
      "Iteration 300: eta = [0.30630294 0.31722039 0.37647666]\n",
      "Iteration 400: eta = [0.57922404 0.02641062 0.39436534]\n",
      "Classification estimée :  [1 1 0 0 1 1 0 0 0 2 0 2 0 2 1 0 0 2 2 2 1 0 0 0 0 1 1 2 0 0 0 2 2 0 1 1 1\n",
      " 0 1 0 2 0 1 1 2 1 1 2 0 1 0 2 0 1 0 0 1 1 1 0 1 0 0 2 2 0 1 1 2]\n",
      "Paramètres des groupes :  [array([-0.47449519,  1.40787666]), array([-0.42231031,  0.51687491]), array([-1.07354007, -1.26681498])]\n",
      "Paramètres eta :  [0.37201194 0.27647577 0.35151229]\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données réelles normalisées sur l'ensemble\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conversion en tableau NumPy\n",
    "y_global = GDP_global.values.T  # Transpose pour avoir (N, T)\n",
    "\n",
    "K = 3  # Nombre de clusters\n",
    "num_iter = 500  # Nombre d'itérations pour le MCMC\n",
    "\n",
    "# Estimation MCMC\n",
    "S_est, theta_est, eta_est = mcmc_arma(y_global, K, 2, 0, num_iter)\n",
    "\n",
    "print(\"Classification estimée : \", S_est)\n",
    "print(\"Paramètres des groupes : \", theta_est)\n",
    "print(\"Paramètres eta : \", eta_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: eta = [0.44378555 0.52489075 0.0313237 ]\n",
      "Iteration 100: eta = [0.10782093 0.81020489 0.08197418]\n",
      "Iteration 200: eta = [0.00443055 0.99327433 0.00229511]\n",
      "Iteration 300: eta = [0.02644586 0.06236321 0.91119093]\n",
      "Iteration 400: eta = [0.12910007 0.86849781 0.00240211]\n",
      "Classification estimée :  [2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2]\n",
      "Paramètres des groupes :  [array([-0.26180907,  0.35715229]), array([ 0.13350516, -0.22636144]), array([-0.57130212, -1.56560738])]\n",
      "Paramètres eta :  [0.05955011 0.01606546 0.92438443]\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données réelles normalisées sur l'ensemble\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conversion en tableau NumPy\n",
    "y = GDP.values.T  # Transpose pour avoir (N, T)\n",
    "\n",
    "K = 3  # Nombre de clusters\n",
    "num_iter = 500  # Nombre d'itérations pour le MCMC\n",
    "\n",
    "# Estimation MCMC\n",
    "S_est, theta_est, eta_est = mcmc_arma(y, K, 2, 0, num_iter)\n",
    "\n",
    "print(\"Classification estimée : \", S_est)\n",
    "print(\"Paramètres des groupes : \", theta_est)\n",
    "print(\"Paramètres eta : \", eta_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimer le nombre optimal de clusters K\n",
    "\n",
    "en utilisant une prior uniforme pour M_k : Pr(MK)= 1/Kmax\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape 1 : Bridge Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "def bridge_sampling(log_posterior, log_prior, proposal_density, posterior_samples, proposal_samples):\n",
    "    \"\"\"\n",
    "    Implémente la méthode de bridge sampling pour estimer la vraisemblance marginale.\n",
    "    log_posterior: fonction qui calcule le log de la densité postérieure\n",
    "    log_prior: fonction qui calcule le log de la prior\n",
    "    proposal_density: fonction qui calcule la densité de la proposition\n",
    "    posterior_samples: échantillons de la distribution postérieure (MCMC)\n",
    "    proposal_samples: échantillons de la distribution de proposition (iid)\n",
    "    \"\"\"\n",
    "    # Calcul des poids de bridge\n",
    "    log_w_posterior = log_posterior(posterior_samples) + log_prior(posterior_samples) - proposal_density(posterior_samples)\n",
    "    log_w_proposal = log_posterior(proposal_samples) + log_prior(proposal_samples) - proposal_density(proposal_samples)\n",
    "    \n",
    "    w_posterior = np.exp(log_w_posterior)\n",
    "    w_proposal = np.exp(log_w_proposal)\n",
    "    \n",
    "    Z_ratio = np.sum(w_posterior) / np.sum(w_proposal)\n",
    "    marginal_likelihood = np.sum(w_posterior / (Z_ratio + w_posterior))\n",
    "    \n",
    "    return np.log(marginal_likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 2 : Intégration avec MCMC et choix de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_marginal_likelihood(y, K, num_iterations, p, q, e0=1.0):\n",
    "    \"\"\"\n",
    "    Calcule la vraisemblance marginale pour un nombre donné de clusters K.\n",
    "    \"\"\"\n",
    "    # Étape 1 : Échantillonnage MCMC pour le modèle avec K clusters\n",
    "    S, theta, eta = mcmc_arma(y, K, p, q, num_iterations, e0)\n",
    "    \n",
    "    # Étape 2 : Définir les fonctions de log posterior, prior et proposition\n",
    "    def log_posterior(params):\n",
    "        # Placeholder : remplacez par le calcul du log posterior\n",
    "        return -0.5 * np.sum(params**2)\n",
    "    \n",
    "    def log_prior(params):\n",
    "        # Placeholder : prior sur les paramètres\n",
    "        return -0.5 * np.sum(params**2)\n",
    "    \n",
    "    def proposal_density(params):\n",
    "        # Placeholder : densité de proposition gaussienne\n",
    "        return -0.5 * np.sum(params**2)\n",
    "    \n",
    "    # Étape 3 : Générer des échantillons pour bridge sampling\n",
    "    posterior_samples = np.random.randn(1000, len(theta))  # Échantillons postérieurs simulés\n",
    "    proposal_samples = np.random.randn(1000, len(theta))  # Échantillons de proposition\n",
    "    \n",
    "    # Étape 4 : Bridge sampling\n",
    "    log_marginal_likelihood = bridge_sampling(log_posterior, log_prior, proposal_density, posterior_samples, proposal_samples)\n",
    "    return log_marginal_likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 3 : Estimation du nombre optimal de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_optimal_clusters(y, K_max, num_iterations, p, q, e0=1.0):\n",
    "    \"\"\"\n",
    "    Choisit le nombre optimal de clusters en utilisant la vraisemblance marginale.\n",
    "    \"\"\"\n",
    "    log_marginal_likelihoods = []\n",
    "    \n",
    "    for K in range(1, K_max + 1):\n",
    "        log_ml = compute_marginal_likelihood(y, K, num_iterations, p, q, e0)\n",
    "        log_marginal_likelihoods.append(log_ml)\n",
    "        print(f\"K={K}, log marginal likelihood = {log_ml}\")\n",
    "    \n",
    "    optimal_K = np.argmax(log_marginal_likelihoods) + 1\n",
    "    return optimal_K, log_marginal_likelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_optimal_clusters_with_prior(y, K_max, num_iterations, p, q, e0=1.0):\n",
    "    \"\"\"\n",
    "    Choisit le nombre optimal de clusters en utilisant la vraisemblance marginale\n",
    "    avec une prior explicite sur les modèles.\n",
    "    \"\"\"\n",
    "    log_marginal_likelihoods = []\n",
    "    prior_probabilities = [1 / K_max] * K_max  # Prior uniforme\n",
    "\n",
    "    for K in range(1, K_max + 1):\n",
    "        log_ml = compute_marginal_likelihood(y, K, num_iterations, p, q, e0)\n",
    "        log_prior = np.log(prior_probabilities[K - 1])\n",
    "        log_marginal_likelihoods.append(log_ml + log_prior)\n",
    "        print(f\"K={K}, log marginal likelihood + log prior = {log_ml + log_prior}\")\n",
    "\n",
    "    optimal_K = np.argmax(log_marginal_likelihoods) + 1\n",
    "    return optimal_K, log_marginal_likelihoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: eta = [1.]\n",
      "Iteration 100: eta = [1.]\n",
      "Iteration 200: eta = [1.]\n",
      "Iteration 300: eta = [1.]\n",
      "Iteration 400: eta = [1.]\n",
      "Iteration 500: eta = [1.]\n",
      "Iteration 600: eta = [1.]\n",
      "Iteration 700: eta = [1.]\n",
      "Iteration 800: eta = [1.]\n",
      "Iteration 900: eta = [1.]\n",
      "K=1, log marginal likelihood + log prior = -506.63037858262845\n",
      "Iteration 0: eta = [0.26478075 0.73521925]\n",
      "Iteration 100: eta = [0.12587618 0.87412382]\n",
      "Iteration 200: eta = [0.38767076 0.61232924]\n",
      "Iteration 300: eta = [0.79586043 0.20413957]\n",
      "Iteration 400: eta = [0.57810088 0.42189912]\n",
      "Iteration 500: eta = [0.75718219 0.24281781]\n",
      "Iteration 600: eta = [0.68836394 0.31163606]\n",
      "Iteration 700: eta = [0.41571736 0.58428264]\n",
      "Iteration 800: eta = [0.27223669 0.72776331]\n",
      "Iteration 900: eta = [0.64557373 0.35442627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12956\\3997777796.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  Z_ratio = np.sum(w_posterior) / np.sum(w_proposal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.46381527 0.45736827 0.07881646]\n",
      "Iteration 100: eta = [0.06409691 0.69500333 0.24089976]\n",
      "Iteration 200: eta = [0.6727733  0.31035314 0.01687356]\n",
      "Iteration 300: eta = [0.17436685 0.25593848 0.56969467]\n",
      "Iteration 400: eta = [0.00616875 0.56747018 0.42636107]\n",
      "Iteration 500: eta = [0.46233875 0.02578251 0.51187874]\n",
      "Iteration 600: eta = [0.4906374  0.1209427  0.38841989]\n",
      "Iteration 700: eta = [0.00578596 0.48739303 0.50682101]\n",
      "Iteration 800: eta = [0.08652585 0.59293892 0.32053523]\n",
      "Iteration 900: eta = [0.45748703 0.15172928 0.39078368]\n",
      "K=3, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.1210421  0.26068525 0.18595499 0.43231766]\n",
      "Iteration 100: eta = [0.08292567 0.50142407 0.2014924  0.21415787]\n",
      "Iteration 200: eta = [0.37774112 0.06067071 0.16262365 0.39896452]\n",
      "Iteration 300: eta = [0.13146601 0.33642341 0.52084928 0.0112613 ]\n",
      "Iteration 400: eta = [0.28293227 0.16444583 0.29657572 0.25604618]\n",
      "Iteration 500: eta = [0.26243314 0.16666301 0.39859114 0.1723127 ]\n",
      "Iteration 600: eta = [0.66130045 0.12160534 0.19771137 0.01938284]\n",
      "Iteration 700: eta = [0.36469297 0.12480043 0.13108025 0.37942635]\n",
      "Iteration 800: eta = [0.12678862 0.10070367 0.10482725 0.66768045]\n",
      "Iteration 900: eta = [0.55717534 0.12156653 0.25594428 0.06531385]\n",
      "K=4, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.50468764 0.05673208 0.14163445 0.09507843 0.20186741]\n",
      "Iteration 100: eta = [0.68639962 0.06877718 0.19139827 0.00671609 0.04670884]\n",
      "Iteration 200: eta = [0.59100624 0.18534438 0.06412702 0.09147978 0.06804259]\n",
      "Iteration 300: eta = [0.20601761 0.18016392 0.3420239  0.01309893 0.25869564]\n",
      "Iteration 400: eta = [0.14468975 0.06428946 0.05299521 0.56801963 0.17000594]\n",
      "Iteration 500: eta = [0.10567267 0.24424688 0.4065401  0.05870803 0.18483232]\n",
      "Iteration 600: eta = [0.01292255 0.21973027 0.31259334 0.21577814 0.2389757 ]\n",
      "Iteration 700: eta = [0.06405275 0.2740786  0.15283758 0.12616307 0.38286801]\n",
      "Iteration 800: eta = [0.15221707 0.16372823 0.13399239 0.40317351 0.14688879]\n",
      "Iteration 900: eta = [0.30078049 0.32838958 0.07979858 0.06178415 0.22924719]\n",
      "K=5, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.07254183 0.16063972 0.02382347 0.47983174 0.02577617 0.23738706]\n",
      "Iteration 100: eta = [0.01763674 0.0819376  0.20296915 0.1828457  0.46805999 0.04655081]\n",
      "Iteration 200: eta = [0.37150676 0.15397138 0.1480755  0.08123797 0.16742513 0.07778326]\n",
      "Iteration 300: eta = [0.31546512 0.05619125 0.15375948 0.05113808 0.02839847 0.3950476 ]\n",
      "Iteration 400: eta = [0.20216113 0.11335408 0.18461898 0.22918755 0.05319584 0.21748242]\n",
      "Iteration 500: eta = [0.26132224 0.42639852 0.08289863 0.02777536 0.19246314 0.00914212]\n",
      "Iteration 600: eta = [0.00986772 0.11107566 0.05937843 0.7629492  0.04958994 0.00713904]\n",
      "Iteration 700: eta = [0.08020033 0.08762457 0.06051856 0.089908   0.45208103 0.2296675 ]\n",
      "Iteration 800: eta = [0.35689998 0.06703292 0.12892851 0.03831302 0.10859173 0.30023383]\n",
      "Iteration 900: eta = [0.20650347 0.09689351 0.12173135 0.49298218 0.0645418  0.01734769]\n",
      "K=6, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.02151633 0.55298784 0.17695941 0.06825607 0.03217684 0.0171322\n",
      " 0.13097131]\n",
      "Iteration 100: eta = [0.09786272 0.05949721 0.04480443 0.40507824 0.31551484 0.02876253\n",
      " 0.04848004]\n",
      "Iteration 200: eta = [0.20773593 0.03063549 0.08443548 0.00847051 0.1958871  0.43864835\n",
      " 0.03418714]\n",
      "Iteration 300: eta = [0.09164608 0.39457525 0.00179753 0.03890055 0.18393097 0.1847848\n",
      " 0.10436482]\n",
      "Iteration 400: eta = [0.30211408 0.14744653 0.04030438 0.32461517 0.02197695 0.06902545\n",
      " 0.09451744]\n",
      "Iteration 500: eta = [0.1006057  0.1814827  0.0172747  0.12700621 0.21699819 0.29420533\n",
      " 0.06242717]\n",
      "Iteration 600: eta = [0.15054048 0.053978   0.14752959 0.03800541 0.18322469 0.10058887\n",
      " 0.32613296]\n",
      "Iteration 700: eta = [0.03549223 0.07390696 0.0875183  0.22992089 0.24629975 0.24541805\n",
      " 0.08144382]\n",
      "Iteration 800: eta = [0.06573942 0.05678552 0.25530567 0.11477036 0.28829671 0.05091576\n",
      " 0.16818657]\n",
      "Iteration 900: eta = [0.20347992 0.07702881 0.03260161 0.14422061 0.03037973 0.5071397\n",
      " 0.00514962]\n",
      "K=7, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.14913652 0.02767396 0.25100376 0.19860036 0.16191243 0.10111857\n",
      " 0.10156969 0.0089847 ]\n",
      "Iteration 100: eta = [0.12053275 0.08909974 0.15487806 0.0007461  0.07258565 0.173835\n",
      " 0.18899764 0.19932507]\n",
      "Iteration 200: eta = [0.35511003 0.03348831 0.13805206 0.01582718 0.36299887 0.02217935\n",
      " 0.02633297 0.04601124]\n",
      "Iteration 300: eta = [0.11714211 0.34998288 0.0838083  0.04971305 0.00225433 0.02913468\n",
      " 0.06271995 0.3052447 ]\n",
      "Iteration 400: eta = [0.1182368  0.06510546 0.19914767 0.11850585 0.03941869 0.1672595\n",
      " 0.1013025  0.19102354]\n",
      "Iteration 500: eta = [0.03706873 0.02012833 0.44490947 0.06301052 0.02250279 0.09489245\n",
      " 0.25222883 0.06525889]\n",
      "Iteration 600: eta = [0.09629473 0.12491132 0.17084484 0.09644262 0.00430315 0.45248676\n",
      " 0.0373968  0.01731978]\n",
      "Iteration 700: eta = [0.0076673  0.35187635 0.10946871 0.15151048 0.1995886  0.03569421\n",
      " 0.05358383 0.09061053]\n",
      "Iteration 800: eta = [0.00500471 0.26545683 0.15312656 0.00924226 0.13600096 0.11220213\n",
      " 0.28107465 0.03789189]\n",
      "Iteration 900: eta = [0.37758641 0.04859957 0.02684934 0.20840705 0.01860819 0.05052459\n",
      " 0.06639902 0.20302582]\n",
      "K=8, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.02371683 0.06947274 0.03430754 0.22694414 0.0211014  0.27132113\n",
      " 0.18399436 0.12447206 0.04466979]\n",
      "Iteration 100: eta = [0.20412243 0.34529035 0.08660369 0.03671553 0.12443705 0.09706272\n",
      " 0.0520618  0.03663205 0.01707438]\n",
      "Iteration 200: eta = [0.02469301 0.03636148 0.11895353 0.17260039 0.01380709 0.1238003\n",
      " 0.03269242 0.37684706 0.10024471]\n",
      "Iteration 300: eta = [0.04016144 0.16603572 0.01352462 0.13376652 0.043829   0.22080599\n",
      " 0.02790501 0.03313557 0.32083614]\n",
      "Iteration 400: eta = [0.37020022 0.00785947 0.00488849 0.07605298 0.07671453 0.13265574\n",
      " 0.01529449 0.16751552 0.14881856]\n",
      "Iteration 500: eta = [0.03654996 0.27770889 0.05654821 0.06845593 0.02264204 0.17496349\n",
      " 0.30114217 0.01999736 0.04199197]\n",
      "Iteration 600: eta = [0.121815   0.08935302 0.02149828 0.04781835 0.30882924 0.02161546\n",
      " 0.24603852 0.06192163 0.0811105 ]\n",
      "Iteration 700: eta = [0.45148357 0.00704857 0.05530685 0.17402467 0.07241721 0.06408883\n",
      " 0.11141052 0.01893312 0.04528665]\n",
      "Iteration 800: eta = [0.10992258 0.04616036 0.02584621 0.07856541 0.00846404 0.49006685\n",
      " 0.0953493  0.10800157 0.03762368]\n",
      "Iteration 900: eta = [0.0319221  0.03828344 0.10758634 0.23222614 0.19391463 0.01072683\n",
      " 0.08297359 0.06754137 0.23482556]\n",
      "K=9, log marginal likelihood + log prior = nan\n",
      "Iteration 0: eta = [0.05165399 0.15189594 0.06256137 0.03469063 0.05167801 0.05002301\n",
      " 0.15238204 0.07099633 0.2125724  0.16154628]\n",
      "Iteration 100: eta = [0.15498804 0.30242762 0.05364462 0.08440043 0.14953888 0.13179743\n",
      " 0.01035244 0.06972183 0.00299979 0.04012894]\n",
      "Iteration 200: eta = [0.08297803 0.01434633 0.05620747 0.08900106 0.0132734  0.21533193\n",
      " 0.07101625 0.11861919 0.05133545 0.28789088]\n",
      "Iteration 300: eta = [0.11296308 0.14244695 0.01864308 0.14630644 0.19709406 0.07272222\n",
      " 0.0293272  0.12444202 0.0231862  0.13286875]\n",
      "Iteration 400: eta = [0.06763071 0.10825043 0.0252753  0.06605335 0.03116341 0.09139787\n",
      " 0.45013398 0.00601216 0.07000054 0.08408227]\n",
      "Iteration 500: eta = [0.12668781 0.06041497 0.31598567 0.19837397 0.13636133 0.02866999\n",
      " 0.00606543 0.0867562  0.01893723 0.0217474 ]\n",
      "Iteration 600: eta = [0.00291001 0.0784433  0.2354391  0.24920366 0.02111605 0.06265493\n",
      " 0.07665378 0.0008853  0.20561102 0.06708286]\n",
      "Iteration 700: eta = [0.00822269 0.07854397 0.01045872 0.01612568 0.20923138 0.04130298\n",
      " 0.20178795 0.12081806 0.02096785 0.29254071]\n",
      "Iteration 800: eta = [0.27972539 0.03143004 0.00430813 0.07073601 0.18686752 0.042645\n",
      " 0.07320736 0.12428428 0.12961633 0.05717994]\n",
      "Iteration 900: eta = [0.02563455 0.10134025 0.1768838  0.16941982 0.00076435 0.09151943\n",
      " 0.11673928 0.08766598 0.21286737 0.01716517]\n",
      "K=10, log marginal likelihood + log prior = nan\n",
      "Nombre optimal de clusters : 2\n"
     ]
    }
   ],
   "source": [
    "# Exécution pour des données réelles normalisées sur l'ensemble\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conversion en tableau NumPy\n",
    "y_global = GDP_global.values.T  # Transpose pour avoir (N, T)\n",
    "K_max = 10\n",
    "num_iterations = 1000\n",
    "p, q = 1, 1\n",
    "\n",
    "optimal_K, log_marginal_likelihoods = choose_optimal_clusters_with_prior(y_global, K_max, num_iterations, p, q)\n",
    "print(f\"Nombre optimal de clusters : {optimal_K}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
